{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c665e39",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a5971",
   "metadata": {},
   "source": [
    "- gender 성별\n",
    "- age 나이\n",
    "- height 키\n",
    "- weight 몸무게\n",
    "- eyesight(left, right) 왼쪽 시력, 오른쪽 시력\n",
    "- hearing(left, right) 왼쪽 청력, 오른쪽 청력\n",
    "\n",
    "- systolic 최고혈압(대동맥 내로 보내지는 심실 수축기의 혈압)\n",
    "- relaxation 최저혈압\n",
    "- fasting blood sugar 공복혈당\n",
    "- Cholesterol 총 콜레스테롤\n",
    "- triglyceride 중성지방\n",
    "- HDL 고밀도지단백 (콜레스테롤)\n",
    "- LDL 저밀도지단백 (콜레스테롤)\n",
    "- hemoglobin 헤모글로빈 수치\n",
    "- Urine protein 단백뇨\n",
    "- serum creatinine 혈액 또는 소변에서 크레아티닌 양 측정 - *신장*관련\n",
    "\n",
    "- AST 아스파르테이트 아미노 전달효소 *간*\n",
    "- ALT 알라닌 아미노 전달효소 *간* \n",
    "    - AST, ALT의 정상 범위 ~40, 경도 40~ 200, 중등도 200~400, 중증 400~\n",
    "- Gtp 감마 Gtp간 기능 검사 *알코올 관련*\n",
    "    - 정상 ~50, 가벼운 증가 51~100, 중간정도의 증가 101~200, 고도의 증가 201~500, 초고도 증가 500~\n",
    "    - 술 마시지 않는 사람도 높게 나올 수 있다.\n",
    "    \n",
    "- oral 구강검사 여부\n",
    "- dental caries 충치 갯수\n",
    "- tartar 치석존재여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f92eacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e7e9384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a1ec6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55692, 27)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/smoking.csv')\n",
    "df.shape  # (55693, 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7913993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 범주형 데이터 변환\n",
    "df = df.replace({'N':0,'Y':1,'F':0,'M':1, })\n",
    "gender = {'F': 0, 'M': 1}\n",
    "oral = {'N': 0, 'T': 1}\n",
    "tartar = {'N': 0, 'T': 1}\n",
    "# df 전체 float형으로 바꾸기\n",
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c5f4846",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_obe = df.iloc[:, [2,3,4,5, 10,11,12,13,14,15,16]]\n",
    "rename = df_obe.rename(columns={'height(cm)':'height', 'weight(kg)':'weight', 'waist(cm)':'waist'})\n",
    "\n",
    "rename.insert(3, 'BMI', rename['weight']/(rename['height']*rename['height']), 0)\n",
    "\n",
    "target = df.iloc[:,-1]\n",
    "df = pd.concat([rename, target], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec19625",
   "metadata": {},
   "source": [
    "### 3. 훈련01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73816df1",
   "metadata": {},
   "source": [
    "#### scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7fbe61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3a21a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "columns = list(X_train.columns)\n",
    "\n",
    "X_train_minmax = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_minmax, columns = columns)\n",
    "\n",
    "X_test_minmax = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_minmax, columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28742e8a",
   "metadata": {},
   "source": [
    "#### minxax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c108c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "columns = list(X_train.columns)\n",
    "\n",
    "X_train_minmax = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_minmax, columns = columns)\n",
    "\n",
    "X_test_minmax = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_minmax, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8be4026",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "columns = list(X_train.columns)\n",
    "\n",
    "X_train_minmax = scaler.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train_minmax, columns = columns)\n",
    "\n",
    "X_test_minmax = scaler.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test_minmax, columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5035b360",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '2022-11-21 13:43:08'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [68], line 52\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mResults not scaled, Please use : StandardScaler,MinMaxScaler,RobustScaler\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m selectscaler(\u001b[39m'\u001b[39;49m\u001b[39mMinMaxScaler\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn [68], line 30\u001b[0m, in \u001b[0;36mselectscaler\u001b[1;34m(scaler_name)\u001b[0m\n\u001b[0;32m     27\u001b[0m scaler \u001b[39m=\u001b[39m MinMaxScaler()\n\u001b[0;32m     28\u001b[0m columns \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(X_train\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m---> 30\u001b[0m X_train_minmax \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(X_train)\n\u001b[0;32m     31\u001b[0m X_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(X_train_minmax, columns \u001b[39m=\u001b[39m columns)\n\u001b[0;32m     33\u001b[0m X_test_minmax \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:867\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    864\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    865\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    866\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[0;32m    868\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:420\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    418\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 420\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:457\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMinMaxScaler does not support sparse input. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using MaxAbsScaler instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    454\u001b[0m     )\n\u001b[0;32m    456\u001b[0m first_pass \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 457\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    458\u001b[0m     X,\n\u001b[0;32m    459\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_pass,\n\u001b[0;32m    460\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[0;32m    461\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    462\u001b[0m )\n\u001b[0;32m    464\u001b[0m data_min \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmin(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    465\u001b[0m data_max \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnanmax(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\validation.py:856\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    854\u001b[0m         array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mastype(dtype, casting\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munsafe\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    855\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 856\u001b[0m         array \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m    857\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[0;32m    858\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    860\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:2070\u001b[0m, in \u001b[0;36mNDFrame.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2069\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__array__\u001b[39m(\u001b[39mself\u001b[39m, dtype: npt\u001b[39m.\u001b[39mDTypeLike \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m-> 2070\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49masarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_values, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '2022-11-21 13:43:08'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.2, random_state=42)\n",
    "\n",
    "def selectscaler(scaler_name):\n",
    "    global X_train,X_test\n",
    "\n",
    "    if scaler_name == 'StandardScaler':\n",
    "        #StandardScaler\n",
    "        scaler = StandardScaler()\n",
    "        columns = list(X_train.columns)\n",
    "\n",
    "        X_train_minmax = scaler.fit_transform(X_train)\n",
    "        X_train = pd.DataFrame(X_train_minmax, columns = columns)\n",
    "\n",
    "        X_test_minmax = scaler.transform(X_test)\n",
    "        X_test = pd.DataFrame(X_test_minmax, columns = columns)\n",
    "        return print('StandardScaler Results')\n",
    "    \n",
    "    elif scaler_name == \"MinMaxScaler\":\n",
    "        # MinMaxScaler\n",
    "        scaler = MinMaxScaler()\n",
    "        columns = list(X_train.columns)\n",
    "\n",
    "        X_train_minmax = scaler.fit_transform(X_train)\n",
    "        X_train = pd.DataFrame(X_train_minmax, columns = columns)\n",
    "\n",
    "        X_test_minmax = scaler.transform(X_test)\n",
    "        X_test = pd.DataFrame(X_test_minmax, columns = columns)\n",
    "        return print('MinMaxScaler Results')\n",
    "\n",
    "    elif scaler_name == \"RobustScaler\":\n",
    "        # RobustScaler\n",
    "        scaler = RobustScaler()\n",
    "        columns = list(X_train.columns)\n",
    "\n",
    "        X_train_minmax = scaler.fit_transform(X_train)\n",
    "        X_train = pd.DataFrame(X_train_minmax, columns = columns)\n",
    "\n",
    "        X_test_minmax = scaler.transform(X_test)\n",
    "        X_test = pd.DataFrame(X_test_minmax, columns = columns)\n",
    "        \n",
    "        return print('RobustScaler Results')\n",
    "    else:\n",
    "        return print('Results not scaled, Please use : StandardScaler,MinMaxScaler,RobustScaler')\n",
    "\n",
    "selectscaler('MinMaxScaler')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7a3a34",
   "metadata": {},
   "source": [
    "#### 3-2 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15bec77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 19440 candidates, totalling 58320 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19]),\n",
       "                         &#x27;min_impurity_decrease&#x27;: array([0. , 0.3, 0.4]),\n",
       "                         &#x27;min_samples_split&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19]),\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4]),\n",
       "                         &#x27;random_state&#x27;: [42], &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19]),\n",
       "                         &#x27;min_impurity_decrease&#x27;: array([0. , 0.3, 0.4]),\n",
       "                         &#x27;min_samples_split&#x27;: array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19]),\n",
       "                         &#x27;min_weight_fraction_leaf&#x27;: array([0. , 0.1, 0.2, 0.3, 0.4]),\n",
       "                         &#x27;random_state&#x27;: [42], &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]},\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19]),\n",
       "                         'min_impurity_decrease': array([0. , 0.3, 0.4]),\n",
       "                         'min_samples_split': array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
       "       19]),\n",
       "                         'min_weight_fraction_leaf': array([0. , 0.1, 0.2, 0.3, 0.4]),\n",
       "                         'random_state': [42], 'splitter': ['best', 'random']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_params :  {'criterion': 'gini', 'max_depth': 19, 'min_impurity_decrease': 0.0, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}\n",
      "best_score_ :  0.7113774605526003\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "from MyModule import girdcvconv as gc\n",
    "\n",
    "\n",
    "estimator = DecisionTreeClassifier()\n",
    "\n",
    "criterion_list =  ['gini','entropy'] \n",
    "splitter_list =  ['best','random']\n",
    "max_depth_list =  np.arange(2, 20)\n",
    "min_samples_split_list = np.arange(2, 20)                                   # 노드 분할 위한 최소 표본수 작으면 과적합, 반대의 경우 과소적합\n",
    "min_weight_fraction_leaf_list =  np.append(0.0,np.arange(0.1, 0.5, 0.1))    # 비율 커지면 과대적합 줄어듬 0,5보다 작게 해야한다\n",
    "min_impurity_decrease_list = np.append(0.0,np.arange(0.3, 0.5, 0.1))        # 비율 노드분할 관련\n",
    "\n",
    "parameter={\n",
    "    'criterion' : criterion_list ,\n",
    "    'splitter'  : splitter_list,\n",
    "    'max_depth' : max_depth_list,\n",
    "    'min_samples_split' : min_samples_split_list,\n",
    "    'min_weight_fraction_leaf' : min_weight_fraction_leaf_list,    \n",
    "    'min_impurity_decrease' :min_impurity_decrease_list,\n",
    "    'random_state': [42]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(estimator, param_grid=parameter, cv=3, verbose=1, n_jobs=-1, refit=True)\n",
    "# verbose 출력 실행 모듈\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "print('best_params : ', model.best_params_)\n",
    "print('best_score_ : ', model.best_score_)\n",
    "\n",
    "gc.paramsTocsv(data_name='obesity', scaler='StandardScaler', model_name='DecisionTreeClassifier', best_params=model.best_params_, best_score=model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07e54f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 예시\n",
    "# from MyModule import girdcvconv as gc\n",
    "# best_params =  {'criterion': 'gini', 'max_depth': 19, 'min_impurity_decrease': 0.0, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}\n",
    "# best_score_ =  0.7113550153749467\n",
    "# gc.paramsTocsv(data_name='obesity', scaler='StandardScaler', model_name='DecisionTreeClassifier', best_params=best_params, best_score=best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1f5f583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>model_name</th>\n",
       "      <th>scaler</th>\n",
       "      <th>best_score</th>\n",
       "      <th>criterion</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_impurity_decrease</th>\n",
       "      <th>min_samples_split</th>\n",
       "      <th>min_weight_fraction_leaf</th>\n",
       "      <th>random_state</th>\n",
       "      <th>splitter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-21 13:42:55</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.711355</td>\n",
       "      <td>gini</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-21 13:43:08</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.711355</td>\n",
       "      <td>gini</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-21 14:53:29</td>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>0.711377</td>\n",
       "      <td>gini</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date              model_name          scaler  best_score  \\\n",
       "0  2022-11-21 13:42:55  DecisionTreeClassifier  StandardScaler    0.711355   \n",
       "1  2022-11-21 13:43:08  DecisionTreeClassifier  StandardScaler    0.711355   \n",
       "2  2022-11-21 14:53:29  DecisionTreeClassifier  StandardScaler    0.711377   \n",
       "\n",
       "  criterion  max_depth  min_impurity_decrease  min_samples_split  \\\n",
       "0      gini         19                    0.0                  2   \n",
       "1      gini         19                    0.0                  2   \n",
       "2      gini         19                    0.0                  2   \n",
       "\n",
       "   min_weight_fraction_leaf  random_state splitter  \n",
       "0                       0.0            42     best  \n",
       "1                       0.0            42     best  \n",
       "2                       0.0            42     best  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 생성된 dataframe 확인\n",
    "import pandas as pd\n",
    "df = pd.read_csv('./modeldata/obesity.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a1850ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': ['gini'], 'max_depth': [19], 'min_impurity_decrease': [0.0], 'min_samples_split': [2], 'min_weight_fraction_leaf': [0.0], 'random_state': [42], 'splitter': ['best']}\n"
     ]
    }
   ],
   "source": [
    "# 특정 데이터프레임 선택\n",
    "import pandas as pd\n",
    "from MyModule import selectparameter as sp\n",
    "\n",
    "bestparams = sp.selectparam('obesity',0)\n",
    "print(bestparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fb18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DecisionTreeClassifier 최적의 파라미터를 바로 삽입\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = DecisionTreeClassifier()\n",
    "model = GridSearchCV(estimator, param_grid=bestparams, cv=3, verbose=1, n_jobs=-1, refit=True)\n",
    "# verbose 출력 실행 모듈\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scikitplot as skplt\n",
    "\n",
    "pred = model.predict(X_test)\n",
    "# 실제 , 예측\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "print('confusion_matrix : \\n', cm)\n",
    "\n",
    "skplt.metrics.plot_confusion_matrix(y_test,pred,figsize=(8,6))\n",
    "plt.show()\n",
    "\n",
    "cl_report = metrics.classification_report(y_test,pred)\n",
    "print('리포트:\\n',cl_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9915103e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0acaf148705ed9ed86cc5cad12259d7985e30670e5686e5f55604a9b3b84a55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
